import torch
print("ğŸ” PyTorch version:", torch.__version__)
print("ğŸ§  CUDA available :", torch.cuda.is_available())
if torch.cuda.is_available():
    print("ğŸš€ GPU ì´ë¦„:", torch.cuda.get_device_name(0))
    print("ğŸ§® ë©”ëª¨ë¦¬:", round(torch.cuda.get_device_properties(0).total_memory / 1024**3, 2), "GB")
else:
    print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€: CPUë¡œë§Œ ì—°ì‚°ë©ë‹ˆë‹¤.")
